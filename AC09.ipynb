{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmjIJHHs/WESrAmEbQ9fX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabucado/2021-1/blob/master/AC09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio de Trabajo en Clases 09: Reconocimiento de Objetos en Proyecto P02"
      ],
      "metadata": {
        "id": "RcTS2MGS09I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basarse en el código anterior y sus parámetros (BATCH, EARLY_STOP, num_epochs, etc.)"
      ],
      "metadata": {
        "id": "Hxp_obyV1g1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import os, sys, fnmatch\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "util = 'pretrain_utils'\n",
        "utilpy = util+'2.py'\n",
        "if os.path.isfile(utilpy):\n",
        "  del sys.modules[util]\n",
        "  os.remove(utilpy)\n",
        "  print(util+' removed.')\n",
        "print(util+' ready to load.')\n",
        "\n",
        "!wget https://www.dropbox.com/s/5nnub5axbj20e2m/pretrain_utils2.py\n",
        "!cp pretrain_utils2.py pretrain_utils.py\n",
        "from pretrain_utils import loaderdef,modeldef,showimages,evaluate,megatrain,printaccm,get_predictions,plot_confusion_matrix\n",
        "print('pretrain_utils module has been loaded')\n",
        "\n",
        "!pip install Augmentor\n",
        "import Augmentor\n",
        "\n",
        "# INCLUDE HERE THE AUGMENTATION FUNCTIONS\n",
        "def augment(PATH_ORIGINAL, PATH_AUGMENTED, set_name, N):\n",
        "  ldir = dirdir(PATH_ORIGINAL+set_name)\n",
        "  for i in range(len(ldir)):\n",
        "    print('processing '+ldir[i])\n",
        "    p0 = Augmentor.Pipeline(PATH_ORIGINAL+set_name+'/'+ldir[i],output_directory='../../../'+PATH_AUGMENTED+set_name+'/'+ldir[i])\n",
        "    p0.set_seed(0)\n",
        "    #p0.rotate90(probability=0.25)\n",
        "    #p0.rotate180(probability=0.25)\n",
        "    #p0.rotate270(probability=0.25)\n",
        "    p0.flip_left_right(probability=0.5)\n",
        "    #p0.skew(probability=0.5)\n",
        "    #p0.flip_random(probability=0.25)\n",
        "    p0.sample(N)\n",
        "\n",
        "def dirfiles(fpath,fext):\n",
        "    fnames = fnmatch.filter(sorted(os.listdir(fpath)),fext)\n",
        "    if '.DS_Store' in fnames:\n",
        "        fnames.remove('.DS_Store')\n",
        "    return fnames\n",
        "def dirdir(fpath):\n",
        "    fnames = sorted(os.listdir(fpath))\n",
        "    if '.DS_Store' in fnames:\n",
        "        fnames.remove('.DS_Store')\n",
        "    return fnames\n",
        "\n",
        "def imagesxclass(fpath,fext='*.jpg'):\n",
        "  fdir = dirdir(fpath)\n",
        "  for i in range(len(fdir)):\n",
        "    x = dirfiles(fpath+'/'+fdir[i]+'/',fext)\n",
        "    print(i,fdir[i],len(x))\n",
        "\n",
        "\n",
        "clear_output()\n"
      ],
      "metadata": {
        "id": "cYHTPwg51815"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Lectura de la base de datos del proyecto\n",
        "\n",
        " La base de datos está en el siguiente enlace:\n",
        " https://www.dropbox.com/s/0ezq2uv1c4wff9y/mochis.zip\n"
      ],
      "metadata": {
        "id": "FjIoi0O31jym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"./mochis\"):\n",
        "  os.system(\"\"\" wget https://www.dropbox.com/s/0ezq2uv1c4wff9y/mochis.zip && unzip -qq mochis.zip && rm mochis.zip \"\"\")\n",
        "  print(\"Datos descargados exitosamente\")\n",
        "print(\"Datos listos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B6ndpf99aLG",
        "outputId": "99434f73-1e63-4188-ff48-26a6be76674e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos descargados exitosamente\n",
            "Datos listos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Despliegue de imagen de ejemplo y sus *bounding boxes*.\n",
        "\n",
        "Se desplegará la imagen "
      ],
      "metadata": {
        "id": "Wo_MXmUM-olo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format_path = lambda g, d, i: f\"G{g:02}_{d}{i:03}.png\"\n",
        "imgpath = format_path(6, 3, 1)\n",
        "img = cv2"
      ],
      "metadata": {
        "id": "XW-psCDK-782"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basarse en el código anterior y sus parámetros (BATCH, EARLY_STOP, num_epochs, etc.)\n",
        "\n",
        "1) [1 punto] Lea la base de datos del proyecto 'mochis' disponible aquí: \n",
        "\n",
        "https://www.dropbox.com/s/0ezq2uv1c4wff9y/mochis.zipEnlaces a un sitio externo.\n",
        "\n",
        "2) [1 punto] Despliegue alguna imagen con sus bounding boxes (cada tipo de objeto en un color distinto, ejemplo: mochila-rojo, cabeza-verde, persona-azul).\n",
        "\n",
        "3) [4 puntos] Genere la Base de Datos para clasificación entre objetos masculinos/femeninos:\n",
        "\n",
        "Escoja 500 imágenes de la base de datos 'mochis'\n",
        "De estas 500 imágenes, 70% serán destinadas a training, 10% a validation y 20% a testing.\n",
        "Escoja un objeto a clasificar (mochila, cabeza, o persona)\n",
        "Construya la base de datos con imágenes de 64x64 pixeles del objeto seleccionado\n",
        "4) [4 puntos] Genere una nueva base de datos balanceada en el training y en validation usando la librería \"Augmentor\" (el conjunto de testing no se cambia, debe contener sólo imágenes reales, no aumentadas)\n",
        "\n",
        "5) [2 puntos] Usando la función \"loaderdef\", cargue los datos de training/validation/testing de esta nueva base de datos de tal forma que no se generen imágenes invertidas.\n",
        "\n",
        "6) [5 puntos] Entrene al menos los siguientes tres modelos:\n",
        "\n",
        "CNN small (cnn-s)\n",
        "VGG-19\n",
        "ResNet-34\n",
        "7) [1 punto] Encuentre la Matriz de Confusión en el Testing del mejor modelo"
      ],
      "metadata": {
        "id": "NCeb8QMz0fev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvnttCUd0Zpq"
      },
      "outputs": [],
      "source": []
    }
  ]
}